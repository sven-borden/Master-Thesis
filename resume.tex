\section*{Abstract}
\addcontentsline{toc}{chapter}{\protect\numberline{}Abstract}%
    A multistable mechanism is a specific mechanism able to hold more than one stable state with zero force. Multistable mechanism devices find application in valves, switches, closures and clasps. They need to be able to store and release energy at specific positions. Bistable and multistable systems generally involve a combination of springs and are attractive from multiple points of view as they can be small and scalable.\\
    
    A previous four legged robot was built in the Bertoldi Group with specific multistable joints as legs. This multistable joint is based on two bistable elements in series. The bistable element consists of two rectangular blocks linked together using a parallelogram linkage to constrain the top block's displacement. A linear spring creates the bistable effect by creating one or two local energy minima. The multistable joint is controlled using a cyclic actuation that displaces both blocks from left to right to left. Depending on the configuration, it is possible to create different types of sequences with the same actuation. Some sequences will allow the bottom bistable structure to snap before the top bistable structure, some other sequences will reverse this process. There are ten possible sequences for each quadristable joint and as the four legs are controlled using only two actuators, there are $40'000$ possible motions for the robot.\\
    
    This thesis creates a workflow from the simulation to the controller to characterize the behavior of a multistable based legged robot. The first step involves the implementation of the leg motions as they are producing non symmetrical cyclic patterns. The second step is the friction model and the simulation of the robot's behavior under specific parameters, such as sequence used and phase difference in the actuation. Finally, a Deep Q Learning based controller takes all the possible cases from the simulation as input to solve trajectory planning problems. \\
    
    The simulation implemented was validated with basics experiments specifically for two types of sequences to produce forward and backward motion. The robot's behavior is very similar in both cases. The flexibility of the model allows to fine-tuned it to real experiments. It is also demonstrated from the simulation that the robot should be able to move forward, backward and change its orientation from about $\pm 6$Â° in one cycle. The Deep Q Learning controller is working better than expected, especially when the number of possible sequences is limited. It can learn the robot's controls in about 40 iterations that translate in a few minutes of live simulation. The controller first learns to reach the specific goal and then reduces the number of sequence change required to reach the objectives. The Controller is also able to learn to control correctly the robot with all sequences enabled but the learning curve is slower, as the possibilities rise exponentially.